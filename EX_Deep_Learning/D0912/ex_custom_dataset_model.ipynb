{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 사용자 정의 데이터셋과 모델과 학습\n",
    "- iris.csv ==> 사용자 정의 데이터셋\n",
    "- DNN 모델 ==> 사용자 정의 모델 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] 모듈 로딩 및 데이터 준비 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 로딩\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchmetrics.classification import F1Score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchinfo import summary\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder      # 타겟 컬럼 수치화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터\n",
    "DATA_FILE='../data/iris.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width variety\n",
       "0           5.1          3.5           1.4          0.2  Setosa\n",
       "1           4.9          3.0           1.4          0.2  Setosa"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CSV ==> DataFrame\n",
    "irisDF=pd.read_csv(DATA_FILE)\n",
    "irisDF.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 컬럼 수치화 ==> LabelEncoder\n",
    "encoder=LabelEncoder()\n",
    "encoder.fit(irisDF['variety'])\n",
    "irisDF['variety']=encoder.transform(irisDF['variety'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] 사용자 정의 데이터셋 클래스 생성 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ----------------------------------------------------\n",
    "# 함수기능 : 파일 확장자별 데이터프레임 변환 가능\n",
    "# 함수이름 : convertDataset\n",
    "# 매개변수 : data_path\n",
    "# 함수결과 : DataFrame\n",
    "#  ----------------------------------------------------\n",
    "\n",
    "def convertDataFrame(data_path, exit_header=0):\n",
    "    ext=data_path.rsplit('.')[-1]\n",
    "    if ext == 'csv':\n",
    "        return pd.read_csv(data_path, header=exit_header)\n",
    "    elif ext=='json':\n",
    "        return pd.read_json(data_path, header=exit_header)\n",
    "    elif ext in ['xlsx', 'xls']:\n",
    "        return pd.read_excel(data_path, header=exit_header)\n",
    "    else:\n",
    "        return pd.read_table(data_path, header=exit_header)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataSet(Dataset):\n",
    "    # 데이터 로딩 및 전처리 진행과 인스턴스 생성 메서드\n",
    "    def __init__(self, featureDF, targetDF):\n",
    "        super().__init__()\n",
    "        self.featureDF = featureDF\n",
    "        self.targetDF = targetDF\n",
    "        self.n_rows = featureDF.shape[0]\n",
    "        self.n_features = featureDF.shape[-1]\n",
    "\n",
    "    # 데이터의개수 반환 메서드\n",
    "    def __len__(self):\n",
    "        return self.n_rows\n",
    "    \n",
    "    # 특정 index의 데이터와 타겟 반환 메서드\n",
    "    def __getitem__(self, idx):\n",
    "        featureTS = torch.FloatTensor( self.featureDF.iloc[idx].values )\n",
    "        targetTS = torch.FloatTensor( self.targetDF.iloc[idx].values )\n",
    "        return featureTS, targetTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------\n",
    "# 클래스기능 : 파일기반 데이터셋\n",
    "# 클래스이름 : FileDataset\n",
    "# 매개변수 : data_path 파일 경로\n",
    "# 부모클래스 : utils.data.Dataset\n",
    "#---------------------------------------------------------------------\n",
    "class CustomDataset(Dataset):\n",
    "    # 데이터 로딩 및 전처리 진행과 인스턴스 생성 메서드\n",
    "    def __init__(self, data_path):\n",
    "        super().__init__()\n",
    "        # 데이터파일 ==> DataFrame 변환\n",
    "        dataDF=convertDataFrame(data_path)\n",
    "        # DataFrame ==> 피쳐와 타겟 추출\n",
    "        self.featureDF=dataDF[dataDF.columns[:-1]]\n",
    "        self.targetDF=dataDF[dataDF.columns[-1:]]\n",
    "\n",
    "        self.n_features=dataDF.shape[1]\n",
    "        self.n_rows=self.featureDF.shape[0]\n",
    "\n",
    "        \n",
    "    # 데이터의 개수 반환 메서드\n",
    "    def __len__(self):\n",
    "        return self.n_rows\n",
    "\n",
    "    # 특정 index의 데이터와 타겟 반환 메서드 => Tensor 반환!!\n",
    "    def __getitem__(self, idx):\n",
    "        featureTS=torch.FloatTensor(self.featureDF.iloc[idx].values)\n",
    "        targetTS=torch.FloatTensor(self.targetDF.iloc[idx].values)\n",
    "        return featureTS, targetTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] 데이터셋 인스턴스 생성 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featureDF => (150, 4), targetDF => (150, 1)\n"
     ]
    }
   ],
   "source": [
    "# 피쳐와 타겟 추출\n",
    "featureDF, targetDF=irisDF[irisDF.columns[:-1]], irisDF[[irisDF.columns[-1]]]\n",
    "print(f'featureDF => {featureDF.shape}, targetDF => {targetDF.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# IRIS 데이터셋 인스턴스 생성\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m irisDS\u001b[38;5;241m=\u001b[39m\u001b[43mCustomDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatureDF\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargetDF\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "# IRIS 데이터셋 인스턴스 생성\n",
    "irisDS=CustomDataset(featureDF, targetDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 150)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IRIS 데이터셋 속성\n",
    "irisDS.n_features, irisDS.n_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5.1000, 3.5000, 1.4000, 0.2000]), tensor([0.]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IRIS 데이터셋 메서드\n",
    "irisDS[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] 데이터로더 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'irisDS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## 필요한 것 : Dataset 인스턴스, Batch_Size\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m irisDL\u001b[38;5;241m=\u001b[39mDataLoader(\u001b[43mirisDS\u001b[49m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'irisDS' is not defined"
     ]
    }
   ],
   "source": [
    "## 필요한 것 : Dataset 인스턴스, Batch_Size\n",
    "irisDL=DataLoader(irisDS, batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4]) torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "for dataTS, targetTS in irisDL:\n",
    "    print(dataTS.shape, targetTS.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[5] 모델 준비 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# 모델이름 : CustomModel\n",
    "# 부모클래스 : nn.Module\n",
    "# 매개변수 : None\n",
    "# 모델 구조\n",
    "# - 입력층 : 입력 4개  출력 10개        AF ReLU -> LeakyReLU\n",
    "# - 은닉층 : 입력 10개  출력 30개       AF ReLU -> LeakyReLU\n",
    "# - 출력층 : 입력 30개  출력 3개        AF 분류 - 다중 분류 Softmax\n",
    "# --------------------------------------------------------------------------\n",
    "class CustomModel(nn.Module):\n",
    "    # 모델 구성 및 인스턴스 생성 메서드\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.in_layer=nn.Linear(4,10)\n",
    "        self.hidden_layer=nn.Linear(10,30)\n",
    "        self.out_layer=nn.Linear(30,3)\n",
    "\n",
    "    # 순방향 학습 메서드\n",
    "    def forward(self, x):\n",
    "        y=F.relu(self.in_layer(x))\n",
    "        y=F.relu(self.hidden_layer(y))\n",
    "        return F.softax(self.out_layer(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomModel(\n",
      "  (in_layer): Linear(in_features=4, out_features=10, bias=True)\n",
      "  (hidden_layer): Linear(in_features=10, out_features=30, bias=True)\n",
      "  (out_layer): Linear(in_features=30, out_features=3, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "CustomModel                              --\n",
       "├─Linear: 1-1                            50\n",
       "├─Linear: 1-2                            330\n",
       "├─Linear: 1-3                            93\n",
       "=================================================================\n",
       "Total params: 473\n",
       "Trainable params: 473\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 모델 인스턴스 생성\n",
    "model=CustomModel()\n",
    "print(model)\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[6] 학습 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'irisDL' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## 배치크기만큼 데이터와 타겟 추출해서 학습 진행\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataTS, targetTS \u001b[38;5;129;01min\u001b[39;00m \u001b[43mirisDL\u001b[49m:\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# 배치크기 만큼의 학습 ㅔ이터\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(dataTS\u001b[38;5;241m.\u001b[39mshape, targetTS\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# 배치크기만큼 학습 진행\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'irisDL' is not defined"
     ]
    }
   ],
   "source": [
    "## 배치크기만큼 데이터와 타겟 추출해서 학습 진행\n",
    "TS_loss, TS_score=[],[]\n",
    "for epoch in range(10):\n",
    "    loss_total, score_total=0,0\n",
    "    for dataTS, targetTS in irisDL:\n",
    "\n",
    "        # 배치크기 만큼의 학습 데이터\n",
    "        print(dataTS.shape, targetTS.shape)\n",
    "        \n",
    "        # 배치크기만큼 학습 진행\n",
    "        pre_y=model(dataTS)\n",
    "        print(pre_y.shape, targetTS.reshape(-1).shape)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss=nn.CrossEntropyLoss()(pre_y, targetTS)\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
