{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kdp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\kdp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<WordListCorpusReader in 'C:\\\\Users\\\\kdp\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora\\\\stopwords'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stopwords 불러오기\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# 내가 설정한 stopwords 추가\n",
    "custom_stopwords = set()\n",
    "with open(r\"C:\\Users\\kdp\\Desktop\\Work_권도운\\개인프로젝트\\STOPWORDS.txt\", 'r', encoding='utf-8') as f:\n",
    "    custom_stopwords = {word.strip().lower() for line in f for word in line.split(', ')}\n",
    "stop_words.update(custom_stopwords)\n",
    "stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCENE I. Athens. A room in the Palace of Theseus</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Enter Theseus, Hippolyta, Philostrate and Att...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THESEUS.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Now, fair Hippolyta, our nuptial hour\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38251</th>\n",
       "      <td>The weight of this sad time we must obey;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38252</th>\n",
       "      <td>\"Speak what we feel, not what we ought to say.\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38253</th>\n",
       "      <td>The oldest hath borne most; we that are young</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38254</th>\n",
       "      <td>\"Shall never see so much, nor live so long.\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38255</th>\n",
       "      <td>[_Exeunt with a dead march._]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38255 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "1                                                  ACT I      0\n",
       "2       SCENE I. Athens. A room in the Palace of Theseus      0\n",
       "3      \"Enter Theseus, Hippolyta, Philostrate and Att...      0\n",
       "4                                               THESEUS.      0\n",
       "5                \"Now, fair Hippolyta, our nuptial hour\"      0\n",
       "...                                                  ...    ...\n",
       "38251          The weight of this sad time we must obey;      1\n",
       "38252    \"Speak what we feel, not what we ought to say.\"      1\n",
       "38253      The oldest hath borne most; we that are young      1\n",
       "38254       \"Shall never see so much, nor live so long.\"      1\n",
       "38255                      [_Exeunt with a dead march._]      1\n",
       "\n",
       "[38255 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파일 경로 설정 (희극 및 비극 폴더 내 파일 경로)\n",
    "files_comedy = [\n",
    "    r\"C:\\Users\\kdp\\Desktop\\Work_권도운\\개인프로젝트\\A Midsummer Nights Dream.csv\",\n",
    "    r\"C:\\Users\\kdp\\Desktop\\Work_권도운\\개인프로젝트\\As You Like It.csv\",\n",
    "    r\"C:\\Users\\kdp\\Desktop\\Work_권도운\\개인프로젝트\\The Merchant of Venice.csv\",\n",
    "    r\"C:\\Users\\kdp\\Desktop\\Work_권도운\\개인프로젝트\\The Taming of the Shrew.csv\",\n",
    "    r\"C:\\Users\\kdp\\Desktop\\Work_권도운\\개인프로젝트\\Twelfth Night.csv\"\n",
    "]\n",
    "\n",
    "files_tragedy = [\n",
    "    r\"C:\\Users\\kdp\\Desktop\\Work_권도운\\개인프로젝트\\Hamlet.csv\",\n",
    "    r\"C:\\Users\\kdp\\Desktop\\Work_권도운\\개인프로젝트\\Macbeth.csv\",\n",
    "    r\"C:\\Users\\kdp\\Desktop\\Work_권도운\\개인프로젝트\\Othello.csv\",\n",
    "    r\"C:\\Users\\kdp\\Desktop\\Work_권도운\\개인프로젝트\\Romeo and Juliet.csv\",\n",
    "    r\"C:\\Users\\kdp\\Desktop\\Work_권도운\\개인프로젝트\\The Tragedy of King Lear.csv\"\n",
    "]\n",
    "\n",
    "# 데이터를 저장할 리스트 초기화\n",
    "texts = []\n",
    "labels = []\n",
    "\n",
    "# 희극과 비극 데이터를 불러와서 라벨링\n",
    "for file_path in files_comedy:\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()  # 공백 제거\n",
    "            if line:  # 빈 줄이 아닌 경우만 추가\n",
    "                texts.append(line)\n",
    "                labels.append(0)  # 희극 : 0\n",
    "\n",
    "for file_path in files_tragedy:\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()  # 공백 제거\n",
    "            if line:  # 빈 줄이 아닌 경우만 추가\n",
    "                texts.append(line)\n",
    "                labels.append(1)  # 비극 : 1\n",
    "\n",
    "# 데이터프레임 생성\n",
    "df = pd.DataFrame({'text': texts, 'label': labels})\n",
    "df=df.drop(0, axis=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>room palace</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fair nuptial hour</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38251</th>\n",
       "      <td>weight sad time must obey</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38252</th>\n",
       "      <td>speak feel ought say</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38253</th>\n",
       "      <td>oldest hath borne young</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38254</th>\n",
       "      <td>shall never see much live long</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38255</th>\n",
       "      <td>dead march</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38255 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 text  label\n",
       "1                                          0\n",
       "2                         room palace      0\n",
       "3                                          0\n",
       "4                                          0\n",
       "5                   fair nuptial hour      0\n",
       "...                               ...    ...\n",
       "38251       weight sad time must obey      1\n",
       "38252            speak feel ought say      1\n",
       "38253         oldest hath borne young      1\n",
       "38254  shall never see much live long      1\n",
       "38255                      dead march      1\n",
       "\n",
       "[38255 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전처리하는 함수 정의\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # 특수문자 제거\n",
    "    text = text.lower()  # 소문자로 변환\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]  # stopwords 제거\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Stopwords를 제거하는 함수 정의\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Stopwords 제거하여 전처리된 텍스트 추가\n",
    "df['text'] = df['text'].apply(remove_stopwords)\n",
    "df['text']=df['text'].apply(preprocess_text)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>room palace</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fair nuptial hour</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>draws apace four happy days bring</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>another moon oh slow</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>moon wanes lingers desires</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31355</th>\n",
       "      <td>weight sad time must obey</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31356</th>\n",
       "      <td>speak feel ought say</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31357</th>\n",
       "      <td>oldest hath borne young</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31358</th>\n",
       "      <td>shall never see much live long</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31359</th>\n",
       "      <td>dead march</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31360 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    text  label\n",
       "0                            room palace      0\n",
       "1                      fair nuptial hour      0\n",
       "2      draws apace four happy days bring      0\n",
       "3                   another moon oh slow      0\n",
       "4             moon wanes lingers desires      0\n",
       "...                                  ...    ...\n",
       "31355          weight sad time must obey      1\n",
       "31356               speak feel ought say      1\n",
       "31357            oldest hath borne young      1\n",
       "31358     shall never see much live long      1\n",
       "31359                         dead march      1\n",
       "\n",
       "[31360 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(subset=['text'])  # 'text' 열에서 비어 있는 행 제거\n",
    "df = df[df['text'].str.strip() != '']  # 빈 문자열 제거\n",
    "df=df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 사전 크기: 14050\n"
     ]
    }
   ],
   "source": [
    "# 단어 사전 생성 및 저장\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(df['text'])\n",
    "word_index = vectorizer.vocabulary_\n",
    "\n",
    "# 단어 사전을 JSON 형식으로 저장\n",
    "with open(r\"C:\\Users\\kdp\\Desktop\\Work_권도운\\개인프로젝트\\texts\\vocab.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(word_index, f, ensure_ascii=False)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"단어 사전 크기: {len(word_index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 사전 불러오기 및 모델 학습\n",
    "\n",
    "# 저장된 단어 사전 불러오기\n",
    "with open(r\"C:\\Users\\kdp\\Desktop\\Work_권도운\\개인프로젝트\\texts\\vocab.json\", 'r', encoding='utf-8') as f:\n",
    "    word_index = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(vocabulary=word_index)\n",
    "X = vectorizer.fit_transform(df['text']).toarray()\n",
    "y = df['label'].values\n",
    "\n",
    "# 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kdp\\anaconda3\\envs\\TORCH_TEXT\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 69.05%\n",
      "Cross-validation scores: [0.59805485 0.62946429 0.60299745 0.63966837 0.63536352]\n",
      "Accuracy: 62.11%\n",
      "F1 Score: 0.68\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 로지스틱 회귀 모델 학습\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 예측 및 정확도 평가\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# 검증\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(f\"Accuracy: {scores.mean() * 100:.2f}%\")\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델과 TfidfVectorizer 저장 경로\n",
    "model_path = 'shakespeare_full_model_logistic.pkl'\n",
    "vectorizer_path = 'tfidf_vectorizer.pkl'\n",
    "\n",
    "# 모델과 벡터라이저 저장\n",
    "with open(model_path, 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)\n",
    "\n",
    "with open(vectorizer_path, 'wb') as vectorizer_file:\n",
    "    pickle.dump(vectorizer, vectorizer_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_path, 'rb') as model_file:\n",
    "    model = pickle.load(model_file)\n",
    "\n",
    "with open(vectorizer_path, 'rb') as vectorizer_file:\n",
    "    vectorizer = pickle.load(vectorizer_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분석 결과: 비극\n"
     ]
    }
   ],
   "source": [
    "# 파일로부터 텍스트 읽기\n",
    "def read_text_from_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read().strip()\n",
    "    return text\n",
    "\n",
    "# 텍스트 전처리 및 Tfidf 변환\n",
    "def preprocess_and_vectorize(text, vectorizer):\n",
    "    tfidf_features = vectorizer.transform([text])  # 텍스트를 TF-IDF로 변환\n",
    "    return tfidf_features\n",
    "\n",
    "# 텍스트 분류 함수\n",
    "def classify_text(file_path, vectorizer, model):\n",
    "    text = read_text_from_file(file_path)  # 파일에서 텍스트 읽기\n",
    "    input_tensor = preprocess_and_vectorize(text, vectorizer)  # TF-IDF 변환\n",
    "    prediction = model.predict(input_tensor)[0]  # Scikit-learn 모델로 예측\n",
    "    return \"희극\" if prediction == 0 else \"비극\"\n",
    "\n",
    "# 평가 실행\n",
    "file_path = r\"C:\\Users\\kdp\\Desktop\\Work_권도운\\개인프로젝트\\texts\\All's well that ends well.txt\"  \n",
    "result = classify_text(file_path, vectorizer, model)\n",
    "print(f\"분석 결과: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_TEXT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
